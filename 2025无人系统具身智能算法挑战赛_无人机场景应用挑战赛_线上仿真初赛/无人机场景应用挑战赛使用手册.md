---
typora-copy-images-to: 无人机赛道使用手册.assets
---

# 2025无人系统具身智能算法挑战赛---无人机场景应用挑战赛使用手册

![image-20250722150018396-17534089485941-17537746078281](无人机场景应用挑战赛使用手册.assets/image-20250722150018396-17534089485941-17537746078281.png)





















## 介绍

​	本手册专为"2025无人系统具身智能算法挑战赛"中的无人机场景应用挑战赛参赛队伍设计，提供完整的大模型-无人机协同开发指导手册。手册围绕"视觉感知-决策控制-无人机执行"的技术闭环，帮助参赛者快速构建基于九格大模型的无人机控制系统。

​	本手册采用"理论→工具→实践"的递进式设计,助力参赛团队快速实现"语言指令→场景理解→动作执行"的智能无人机控制闭环,为大赛竞技提供坚实的技术支撑。**

```
# 2025无人系统具身智能算法挑战赛 使用手册限制条款

© 2025 无人系统具身智能算法挑战赛组委会 版权所有

**使用授权范围：**  
本手册仅授权以下主体在赛事期间使用：

1. 经组委会认证的参赛团队队员
2. 赛事官方裁判及技术监督人员
3. 组委会授权的培训导师

**严格禁止事项：**  

-  任何形式的商业性使用或二次销售  
-  向非参赛组织或个人进行传播  
-  改编后用于其他赛事或商业项目  
-  在线平台/文库的公开传播  

**使用约束：**  
手册所含技术方案、赛事规则及数据参数等知识产权归组委会所有，参赛者仅限：

-  赛事筹备期用于技术方案设计参考
-  正式竞赛期间作为操作规范依据
-  赛后总结阶段用于技术复盘分析

**免责声明：**  
本手册内容按"现有状态"提供：
 组委会不承担因手册信息导致的技术方案偏差责任  
 不保证所含方案满足特定技术场景的实施需求  
 对使用后果不承担直接或间接法律责任  

*违反本条款者组委会有权取消参赛资格并追究法律责任*
```

















## 目录

[TOC]







































## （一）环境配置

**本次大赛使用的操作系统为wsl2的ubuntu20.04，这里提供一个wsl2环境下的Ubuntu-20.04包以及一键安装脚本，这个包已经包含了ros-neotic，大模型文件，大模型运行依赖以及比赛代码编译的依赖，安装完成后可以直接运行大模型和完成代码的编译。 **

#### 1.Rflysim仿真环境配置

##### 1.1 RflySim工具链安装

为保证比赛的正常推进，需要各位队员在自己的电脑上提前部署好RflySim工具链，并进行初步测试。

- 计算机性能要求。

  最低要求Intel I7+英伟达RTX3060+16G内存（推荐32G），或等价匹配AMD的配置。

- 系统要求

  支持Windows10 （1903以上）或Windows11系统，不支持Mac（可尝试使用虚拟机）。

- 安装前置

  1）本次比赛不需要安装MATLAB，但是需要安装一个运行库，下载地址https://pan.baidu.com/s/1vVNJLtFIQg7fDrV4p0OeUg?pwd=yzdw。

  2）若想体验RflySim的完整功能，包括底层开发、自动代码生成等，也可以直接安装MATLAB 2022b以上的版本。

- RflySim工具链安装

  1）下载地址：https://pan.baidu.com/s/1sLqFWw1L4GFJH7daGAtN5w?pwd=b122。

  2）注意事项，一定要使用最新版平台，即v4.00-20250723或更新版本，特别是Windows11的电脑，务必更新这个版本。

  3）安装方法，在Windows中加载iso镜像文件，并阅读其中的HowToInstall.pdf，按步骤来即可。核心步骤是两个：

  <img src=".\无人机场景应用挑战赛使用手册.assets\21.png" width="1000"  />

  ​	（1）运行`0.UbuntuWSL\EnableWSL.bat `并重启，来启用WSL功能。注：若Win11系统可能提示wsl 需要update，可直接双击运行`0.UbuntuWSL\wsl.2.4.13.0.x64.msi`来更新。

  ​	（2）双击运行OnekeyScript.exe，并点确认按钮，即可一键安装RflySim工具链。大概需要占用45G空间和30分钟。

  4）注意事项：不一定安装在C盘，主要看剩余空间。安装盘至少需要保留50G的剩余空间，若C盘空间足够请使用`C:\PX4PSP`，若不足可安装在`D:\PX4PSP或E:\PX4PSP`。

- 学习使用

  安装完成后，请阅读 `[桌面]\RflyTools\HowToUse` 和 API两个快捷方式的内容，一个是学习手册，一个是接口文档。参赛选手请快速遍历并运行`1.RflySimIntro 、2.RflySimUsage、8.RflySimVision`里面的例程。

##### 1.2 WSL2环境导入

- 下载RflyWSL2的压缩包，拷贝到桌面上，解压。地址为https://pan.baidu.com/s/1IzYh-TSWSq3Ok4iNoBV92g?pwd=bxt2。
- 运行EnableWSL2.bat，来启用WSL2，如果提示重启，就重启电脑。
- 运行Install.bat，配置WSL2配置文件并部署RflyWSL2到RflySim工具链环境（请确保 RflySim工具链已安装正常）。
- 将WinWSL2.bat拷贝到任意目录，双击运行，确认下能否在当前目录打开WSL2环境。如拷贝到桌面上，双击打开后显示的目录为挂载的C盘下的桌面目录，输入`ls`列出目录下的文件，可以看到安装的RflyTools工具文件夹和拷贝的WinWSL2.bat脚本。

<img src=".\无人机场景应用挑战赛使用手册.assets\14.png" width="1000"  />

##### 1.3 查看wsl安装的发行版

打开windows终端输入`wsl -l -v`， VERSION 显示为2即为WSL2的，为1则是WSL1下的。

<img src=".\无人机场景应用挑战赛使用手册.assets\41.png" width="1000"  />

#### 2.比赛例程测试

##### 2.1 源代码编译

双击WinWSL2.bat，打开Ubuntu环境，`ls /root`若显示有catkin_ws文件夹先删除该文件夹，使用命令删除`rm -rf /root/catkin_ws`，

<img src=".\无人机场景应用挑战赛使用手册.assets\10.png" width="1000" />

然后再`cd ./demo/linux`，输入`./Build_src.sh`自动拷贝 src.zip 到 catkin_ws 并编译，编译成功界面如下图所示。

<img src=".\无人机场景应用挑战赛使用手册.assets\6.png" width="1000" />

##### 2.2 配置IP地址

修改`/root/catkin_ws/src/Challege_ROS/sensor_pkg/main.py`里面的`TargetIP`为windows端`vEthernet (WSL)`的 IPv4地址，在windows终端输入`ipconfig`查看vEthernet (WSL) IPv4地址：

<img src=".\无人机场景应用挑战赛使用手册.assets\WSL_ipv4.png" width="1000" />

修改`TargetIP`为windows端`vEthernet (WSL)`的 IPv4地址：

<img src=".\无人机场景应用挑战赛使用手册.assets\7.png" width="1000" />

修改 `demo/win/SITLPosStrOnekey.bat`，找到`IS_BROADCAST`将其值修改为wsl2的IP，双击WinWSL2.bat打开wsl2的Ubuntu环境，然后输入`ifconfig`查看wsl2下Ubuntu的IPv4地址：

<img src=".\无人机场景应用挑战赛使用手册.assets\8.png" width="1000" />

<img src=".\无人机场景应用挑战赛使用手册.assets.\ubuntu_ipv4.png" width="1000" />

##### 2.3 运行

双击SITLPosStrOnekey.bat, 等待初始化完成(Rflysim3D出现`CopterSim/PX4 EKF 3DFixed: 1/1`)。

<img src=".\无人机场景应用挑战赛使用手册.assets\9.png" width="1000" />

WinWSL2.bat打开wsl2的Ubuntu环境`cd ./demo/linux` 进入run_temp_try.sh文件目录，然后在终端输入`./run_temp_try.sh`运行机载端程序；

<img src=".\无人机场景应用挑战赛使用手册.assets\12.png" width="1000" />

在`demo/linux`目录下再开起一个wsl2 的 Ubuntu 环境，在其中运行大模型：`python3 test_rflysim.py`，等待大模型加载完毕后，依次输入指令控制无人机运动。

<img src=".\无人机场景应用挑战赛使用手册.assets\58.png" width="1000" />

##### 2.4 二次开发提示

以下表格提供各个模块说明，若想进行二次开发，可对其进行更改，其中大模型与无人机进行交互主要是依赖控制器模块和模型推理指令模块，无人机发送指令后，控制器模块会接受指令信息对无人机进行状态调整，完成指定任务。若想进行更多任务的执行可以在控制器模块进行拓展，同时修改大模型的提示词。

| 功能模块         | 模块说明             | 模块所在路径                                  |
| ---------------- | -------------------- | --------------------------------------------- |
| fast-lio         | 实时激光SLAM定位模块 | catkin_ws/src/faster-lio-main/faster-lio-main |
| ego-planner      | 路径规划与避障       | catkin_ws/src/ego-planner                     |
| yolov5           | ⽬标检测模块         | catkin_ws/src/Challege_ROS/object_det/scripts |
| controller       | 控制器模块           | catkin_ws/src/Challege_ROS/recognize_aruco    |
| recognize_aruceo | ⼆维码检测           | catkin_ws/src/Challege_ROS/controller         |
| test_rflysim.py  | 大模型推理指令       | demo/linux                                    |

## （二）大模型接口

该版本通用大模型参数量为40亿，具有高效训练与推理和高效适配与部署的技术特点，具备文本问答、文本分类、机器翻译、文本摘要等自然语言处理能力。本表聚焦“九格”接口设计中与大模型相关的部分，将其抽象为模型加载、推理调用两大核心单元，具体接口列表如下：

|   接口名称   | 描述                                             |                           调用方式                           |                           输入参数                           |                             输出                             |                      异常处理                      |
| :----------: | ------------------------------------------------ | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :------------------------------------------------: |
| 模型加载接口 | 从本地或远程路径加载大模型及其`Tokenizer`        | `AutoModel.from_pretrained`<br/>`AutoTokenizer.from_pretrained` | \- `model_file` (字符串): 权重与配置存放路径<br/>- `trust_remote_code` (布尔): 是否信任远程自定义代码 | \- `self.model `(模型对象)<br/>- `self.tokenizer `(分词器对象) | 捕获并`rospy.logerr`, 加载失败时置空并退出订阅流程 |
| 推理调用接口 | 根据输入图像与文本`Prompt`，调用模型生成推理结果 |   `model.chat(image=None, msgs, tokenizer=self.tokenizer)`   |                 \- `msgs` (列表): 每项为字典                 |                                                              |                                                    |

#### 1.模型加载接口

```python
self.model = AutoModel.from_pretrained(
    model_file: str,
    trust_remote_code: bool = True,
    attn_implementation: str = 'sdpa',
    torch_dtype: torch.dtype = torch.bfloat16
)
self.tokenizer = AutoTokenizer.from_pretrained(
    model_file: str,
    trust_remote_code: bool = True
)
```

**参数说明**

model_file：本地或远程路径，预训练模型权重与配置所在目录。

trust_remote_code：是否信任并执行仓库中的自定义代码。

attn_implementation 与 torch_dtype：可选优化参数。

**输出说明**

self.model：已加载并 eval() 的模型实例，已切换到 CUDA（若可用）。

self.tokenizer：对应的分词器，用于构造输入 tokens。

**异常处理**

捕获任何加载错误，调用 rospy.logerr("模型加载失败: %s", e) 并将 self.model/self.tokenizer 置为 None，后续流程根据空值判断跳过订阅与推理。

#### 2.推理调用接口

```python
model_res = self.model.chat(
    image=None,
    msgs: List[Dict[str, Any]],
    tokenizer=self.tokenizer
)
```

**输入说明**

msgs：长度可变的消息列表，每条消息格式为：

```python
{
    'role': 'user',
    'content': [pil_image: PIL.Image.Image, prompt: str]
}
```

pil_image：从最新 ROS 彩色帧转换而来。

prompt：用户或上层脚本动态输入的文本提示。

**输出说明**

model_res：大模型返回的推理结果，可为文本、结构化数据或二次封装，随后转换为字符串发布。

**调用时机**

在 self.new_bbox_request == True 且最新图像帧已获取时触发。

**异常处理**

推理过程中捕获任何异常并调用 rospy.logerr("调用大模型进行处理时出错: %s", e)，当前帧推理终止，不影响后续请求。

## （三）无人机接口

#### 1.运行控制接口

本列表列出本次仿真中无人机的ROS话题接口。

| 话题名称                      | 消息类型                          | 发布/订阅 | 功能说明                                                 |
| ----------------------------- | --------------------------------- | --------- | -------------------------------------------------------- |
| `/mavros/local_position/odom` | `nav_msgs::Odometry`              | 订阅      | 接收飞控发布的本地位置和姿态信息                         |
| `/objects`                    | `common_msgs::Objects`            | 订阅      | 获取yolo检测的bbox框                                     |
| `/Aruco`                      | `common_msgs::Aruco`              | 订阅      | 获取二维码检测的信息                                     |
| `/mavros/state`               | `mavros_msgs::State`              | 订阅      | 获取飞控的当前状态（如模式、连接状态、解锁状态）。       |
| `/planning/pos_cmd`           | `quadrotor_msgs::PositionCommand` | 订阅      | 接收规划节点生成的位置指令，用于控制无人机飞行轨迹。     |
| `/Odometry`                   | `nav_msgs::Odometry`              | 订阅      | 接收外部定位系统(FSAT-LIO)的里程计数据，用于坐标系转换。 |
| `/mavros/vision_pose/pose`    | `geometry_msgs::PoseStamped`      | 发布      | 发布无人机在全局坐标系下的位姿                           |
| `/mavros/setpoint_raw/local`  | `mavros_msgs::PositionTarget`     | 发布      | 向飞控发送原始控制指令（位置/速度/加速度目标）           |
| `/move_base_simple/goal`      | `geometry_msgs::PoseStamped`      | 发布      | 发布目标点给规划节点（如穿框任务中的目标位置）。         |
| `/full_points`                | `sensor_msgs::PointCloud2`        | 发布      | 发布完整的点云数据                                       |
| `/mission_command`            | `std_msgs::String`                | 订阅      | 接收大模型任务指令                                       |

##### 1.1 自定义数据格式说明

- **Aruco.msg**

  ```
  std_msgs/Header header 
   
  uint32 id #当前⼆维码对应的数值 
  uint32 cnt_x #⼆维码中⼼在图像上的x⽅向位置 
  uint32 cnt_y #⼆维码中⼼在图像上的y⽅向位置 
  ```

- **Obj.msg**

  ```
  string class_name 
  uint32 left_top_x #框的左上⾓坐标 
  uint32 left_top_y 
  uint32 right_bottom_x #框的右下⾓坐标 
  uint32 right_bottom_y 
  float32 score #⽬标检测的置信度 
  ```

- **Objects.msg**

  ```
  std_msgs/Header header 
  uint8 sensor_id #传感器编号,1:前视，2：下视 
  common_msgs/Obj[] objects #所有检测的⽬标 
  ```

#### 2.相机接口

本表列出了仿真中相机相关的 ROS 话题接口，用于获取深度图、相机参数以及 RGB 图像。

| 话题名称                   | 消息类型           | 发布/订阅 | 功能说明                                         |
| -------------------------- | ------------------ | --------- | ------------------------------------------------ |
| /rflysim/sensor2/img_depth | sensor_msgs::Image | 发布      | 深度相机发布的深度图像数据，用于避障和点云生成。 |
| /rflysim/sensor3/img_rgb   | sensor_msgs::Image | 发布      | 下视RGB相机，用于视觉检测                        |
| /rflysim/sensor1/img_rgb   | sensor_msgs::Image | 发布      | 前视RGB相机，用于视觉检测                        |

